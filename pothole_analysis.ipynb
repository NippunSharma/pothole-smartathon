{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\Large{Smartathon} \\\\\n",
    "\\large{} \\\\\n",
    "\\text{Complete Pothole Analysis from Visual Input} \\\\\n",
    "\\text{Team Name: akatsuki} \\\\\n",
    "\\text{Team Member: Nippun Sharma} \\\\\n",
    "$\n",
    "\n",
    "Email: [inbox.nippun@gmail.com](inbox.nippun@gmail.com)\n",
    "\n",
    "$\n",
    "\\large{Introduction} \\\\\n",
    "\\normalsize{} \\\\\n",
    "\\text{The problem provided is to accurately detect and localize potholes in a given area, just by using a video input stream from} \\\\\n",
    "\\text{a moving car. The challenge itself becomes complicated as we are only allowed to use the video frames to perform any sort of} \\\\\n",
    "\\text{predictions. In this document, I will propose an automated way for detecting, locating, and possibly reconstructing potholes} \\\\\n",
    "\\text{just using the video input. As a proof of concept (PoC), I will also apply most of the discussed techniques on the example video} \\\\\n",
    "\\text{file provided by the organizers.}\n",
    "$\n",
    "<br></br>\n",
    "$\n",
    "\\large{Detection} \\\\\n",
    "\\normalsize{} \\\\\n",
    "\\text{The most straight-forward part of this challenge was to detect potholes i.e. create bounding-boxes around potholes in the} \\\\\n",
    "\\text{video. I used a Yolov5m (medium) model to perform this task. The model was trained on the 2022 version of the Road Damage} \\\\\n",
    "\\text{Detection Dataset. This dataset consists Potholes, Longitudinal Cracks, Transverse Cracks and Aligator Cracks.} \\\\\n",
    "$\n",
    "[This](https://github.com/sekilab/RoadDamageDetector) is the link to github repository of the RDD Dataset.\n",
    "\n",
    "<br></br>\n",
    "$\n",
    "\\large{Tracking} \\\\\n",
    "\\normalsize{} \\\\\n",
    "\\text{In our case we also want to count the total number of unique potholes that were visible in the entire journey.} \\\\\n",
    "\\text{A normal detector will not provide us with unique boxes, as a pothole detected in one frame will also get detected in the next one.} \\\\\n",
    "\\text{Thus counting the total number of detections will lead to a double-counting problem. To tackle this problem, I used detection with} \\\\\n",
    "\\text{tracking. Tracking is the process of assigning a unique identifier to a bounding-box and keeping sure that the box has the same} \\\\\n",
    "\\text{identifier in all subsequent frames. Tracking will prevent the double-counting and we will be able to count the actual number of} \\\\\n",
    "\\text{potholes. I used SORT (Simple Online and Realtime Tracking), which is a computer-vision based algorithm to track bounding boxes.}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.config.config import config\n",
    "from modules.detection.detection import apply_detection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from sort.sort import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_VIDEO = \"demo/sections.mov\"\n",
    "RESULTS_DIR = \"./results\"\n",
    "YOLO_DIR = \"./yolov5\"\n",
    "DETECTION_MODEL = \"./pretrained_model/yolov5.onnx\"\n",
    "\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.mkdir(RESULTS_DIR)\n",
    "\n",
    "if not os.path.exists(Path(RESULTS_DIR) / \"detection\"):\n",
    "    os.mkdir(Path(RESULTS_DIR) / \"detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-1-17 Python-3.9.15 torch-1.13.1 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Loading pretrained_model\\yolov5.onnx for ONNX Runtime inference...\n",
      "Adding AutoShape... \n",
      "100%|██████████| 3844/3844 [03:59<00:00, 16.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# apply detection and tracking on the dummy video here.\n",
    "# output saved in results/detection/section.mp4\n",
    "\n",
    "cap = cv2.VideoCapture(DEMO_VIDEO)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    logging.error(f\"Could not open video file {DEMO_VIDEO}\")\n",
    "    raise\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "out = cv2.VideoWriter((Path(RESULTS_DIR) / \"detection\" / f\"{Path(DEMO_VIDEO).stem}.mp4\").as_posix(),\n",
    "    cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))\n",
    "\n",
    "detections_df = pd.DataFrame(columns=[\"id\", \"frame\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class\"])\n",
    "\n",
    "num_frames = 0\n",
    "\n",
    "# object trackers.\n",
    "pothole_tracker = Sort(max_age=10, min_hits=3)\n",
    "pothole_ids = []\n",
    "\n",
    "long_crack_tracker = Sort(max_age=10, min_hits=3)\n",
    "long_crack_ids = []\n",
    "\n",
    "trans_crack_tracker = Sort(max_age=10, min_hits=3)\n",
    "trans_crack_ids = []\n",
    "\n",
    "alig_crack_tracker = Sort(max_age=10, min_hits=3)\n",
    "alig_crack_ids = []\n",
    "\n",
    "model = torch.hub.load(YOLO_DIR, 'custom', DETECTION_MODEL, source='local')\n",
    "pbar = tqdm(total=length)\n",
    "\n",
    "# iterate over all video frames.\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # perform detection.\n",
    "        result = apply_detection(frame, model)\n",
    "\n",
    "        if result.shape[0] == 0:\n",
    "            detections = np.empty((0,5))\n",
    "            pothole_tracks = pothole_tracker.update(detections)\n",
    "            long_crack_tracks = long_crack_tracker.update(detections)\n",
    "            trans_crack_tracks = trans_crack_tracker.update(detections)\n",
    "            alig_crack_tracks = alig_crack_tracker.update(detections)\n",
    "        else:\n",
    "            detections = result.loc[:, [\"xmin\",\"ymin\",\"xmax\",\"ymax\",\"confidence\"]]\n",
    "            detections[[\"xmin\", \"xmax\"]] = detections[[\"xmin\", \"xmax\"]] * 1920 / 640\n",
    "            detections[[\"ymin\", \"ymax\"]] = detections[[\"ymin\", \"ymax\"]] * 1080 / 640\n",
    "\n",
    "            potholes = detections.loc[result[\"name\"] == \"D40\", :].values\n",
    "            pothole_tracks = pothole_tracker.update(potholes)\n",
    "\n",
    "            long_cracks = detections.loc[result[\"name\"] == \"D00\", :].values\n",
    "            long_crack_tracks = long_crack_tracker.update(long_cracks)\n",
    "\n",
    "            trans_cracks = detections.loc[result[\"name\"] == \"D10\", :].values\n",
    "            trans_crack_tracks = trans_crack_tracker.update(trans_cracks)\n",
    "\n",
    "            alig_cracks = detections.loc[result[\"name\"] == \"D20\", :].values\n",
    "            alig_crack_tracks = alig_crack_tracker.update(alig_cracks)\n",
    "\n",
    "        for track in pothole_tracks:\n",
    "            bbox = track[:4].astype(int)\n",
    "            track_id = track[-1]\n",
    "\n",
    "            if track_id not in pothole_ids:\n",
    "                pothole_ids.append(track_id)\n",
    "\n",
    "            detections_df.loc[len(detections_df)] = [pothole_ids.index(track_id), num_frames, track[0], track[1], track[2], track[3], \"D40\"]\n",
    "\n",
    "            cv2.rectangle(frame, bbox[:2], bbox[2:], (0,0,255), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id} - pothole\", (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "\n",
    "        for track in long_crack_tracks:\n",
    "            bbox = track[:4].astype(int)\n",
    "            track_id = track[-1]\n",
    "\n",
    "            if track_id not in long_crack_ids:\n",
    "                long_crack_ids.append(track_id)\n",
    "\n",
    "            detections_df.loc[len(detections_df)] = [long_crack_ids.index(track_id), num_frames, track[0], track[1], track[2], track[3], \"D00\"]\n",
    "\n",
    "            cv2.rectangle(frame, bbox[:2], bbox[2:], (0,255,0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id} - long. crack\", (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "\n",
    "        for track in trans_crack_tracks:\n",
    "            bbox = track[:4].astype(int)\n",
    "            track_id = track[-1]\n",
    "\n",
    "            if track_id not in trans_crack_ids:\n",
    "                trans_crack_ids.append(track_id)\n",
    "\n",
    "            detections_df.loc[len(detections_df)] = [trans_crack_ids.index(track_id), num_frames, track[0], track[1], track[2], track[3], \"D10\"]\n",
    "\n",
    "            cv2.rectangle(frame, bbox[:2], bbox[2:], (255,0,0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id} - trans. crack\", (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "\n",
    "        for track in alig_crack_tracks:\n",
    "            bbox = track[:4].astype(int)\n",
    "            track_id = track[-1]\n",
    "\n",
    "            if track_id not in alig_crack_ids:\n",
    "                alig_crack_ids.append(track_id)\n",
    "\n",
    "            detections_df.loc[len(detections_df)] = [alig_crack_ids.index(track_id), num_frames, track[0], track[1], track[2], track[3], \"D20\"]\n",
    "\n",
    "            cv2.rectangle(frame, bbox[:2], bbox[2:], (0,0,0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id} - alig. crack\", (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"POTHOLE COUNT: {len(pothole_ids)}\", (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,0), 2)\n",
    "        cv2.putText(frame, f\"LONG. CRACK COUNT: {len(long_crack_ids)}\", (40, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,0), 2)\n",
    "        cv2.putText(frame, f\"TRANS. CRACK COUNT: {len(trans_crack_ids)}\", (40, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,0), 2)\n",
    "        cv2.putText(frame, f\"ALIG. CRACK COUNT: {len(alig_crack_ids)}\", (40, 160), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,0), 2)\n",
    "\n",
    "        pbar.update(1)\n",
    "        num_frames += 1\n",
    "        out.write(frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "detections_df.to_csv(Path(RESULTS_DIR) / \"detection\" / \"detections.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `results/detection` for the generated video file (`sections.mp4`) with bounding boxes and counts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large{} \\\\\n",
    "\\text{Absolute Scale} \\\\\n",
    "\\normalsize{} \\\\\n",
    "\\text{It is well known that the structure-of-motion from a single camera only results in a reconstruction up to a scale. Meaning that, there} \\\\\n",
    "\\text{is no sense of absolute distances (such as metres or centi-meters), all points are relatively placed up to a scale. However, in our} \\\\\n",
    "\\text{case, it is required to measure the actual dimensions of the pothole and find its absolute location within the complete journey} \\\\\n",
    "\\text{travelled by the vehicle. Our problem falls under a special category of SFM where our vehicle puts certain constraints on the camera} \\\\\n",
    "\\text{motion, that are known as non-holonomic constraints. Especially, when the camera is at an offset w.r.t. the car's center of gravity.} \\\\\n",
    "\\text{The solution is based on the physics behind the instantaneous center of rotation (ICR). Basically, any moving object can be considered} \\\\\n",
    "\\text{as rotating about its ICR.} \\\\ \\\\\n",
    "$\n",
    "For an in-depth analysis into the setup and solution, you can read this very interesting [paper](https://rpg.ifi.uzh.ch/docs/ICCV09_scaramuzza.pdf) by Davide Scaramuzza. Below is the code that I have written after reading the paper and I use it for generating an approximate absolute\n",
    "scale value. I have used the least-squares version, which is a 3-point algorithm. Also, as a quick demonstration (when we plot using visual\n",
    "odometry) I have extracted a subset of frames from the demo video where the car is turning around the corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_theta_phi(image_1_pts, image_2_pts):\n",
    "    # find theta and phi angles from image correspondences.\n",
    "    # make sure that there are at-least 3 corresponding pairs.\n",
    "\n",
    "    N = image_1_pts.shape[0]\n",
    "    A = np.zeros((N,4), dtype=float)\n",
    "\n",
    "    A[:,0] = image_1_pts[:,0] * image_2_pts[:,1]\n",
    "    A[:,1] = image_1_pts[:,1] * image_2_pts[:,0]\n",
    "    A[:,2] = image_1_pts[:,2] * image_2_pts[:,1]\n",
    "    A[:,3] = image_1_pts[:,1] * image_2_pts[:,2]\n",
    "\n",
    "    U, S, V = np.linalg.svd(A)\n",
    "    result = V[:,-1]\n",
    "\n",
    "    phi = np.arctan2(result[2], -result[0])\n",
    "    theta = phi + np.arctan2(result[3], result[1])\n",
    "    return theta, phi\n",
    "\n",
    "def normalize_point(point):\n",
    "    # normalize a point about a sphere of radius 1.\n",
    "    R = 1\n",
    "\n",
    "    xAvg = point[:,0].mean()\n",
    "    yAvg = point[:,1].mean()\n",
    "    xy_norm = (((point - np.array([[xAvg, yAvg]])) ** 2).sum(axis=1) ** 0.5).mean()\n",
    "    diagonal_element = (R ** 0.5) / xy_norm\n",
    "    element_13 = -(R ** 0.5) * xAvg / xy_norm\n",
    "    element_23 = -(R ** 0.5) * yAvg / xy_norm\n",
    "    norm_mat = np.array([[diagonal_element, 0, element_13], [0, diagonal_element, element_23], [0, 0, 1]])\n",
    "    point = np.concatenate([point, np.ones((point.shape[0],1))], axis=1)\n",
    "    return norm_mat.dot(point.T).T\n",
    "\n",
    "def absolute_scale(images):\n",
    "    # maximum frames to lookahead to find a valid match.\n",
    "    MAX_LOOKAHEAD = 15\n",
    "\n",
    "    # threshold for theta.\n",
    "    THETA_THRES = 30\n",
    "\n",
    "    # this is the offset value of the camera from the Center of Gravity of the car.\n",
    "    # I have taken the same value as is taken in paper.\n",
    "    # The value is in meters.\n",
    "    D_COM = 0.9 \n",
    "\n",
    "    left = 0\n",
    "    right = 1\n",
    "    N = len(images)\n",
    "    curvatures = []\n",
    "\n",
    "    pbar = tqdm(total=N)\n",
    "\n",
    "    # generate a list of valid curvatures.\n",
    "    while(right < N):\n",
    "        img1 = cv2.cvtColor(images[left], cv2.COLOR_RGB2GRAY)\n",
    "        img2 = cv2.cvtColor(images[right], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        orb = cv2.ORB_create(3000)\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(indexParams=index_params, searchParams=search_params)\n",
    "\n",
    "        kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "        kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Find the matches there do not have a to high distance\n",
    "        good = []\n",
    "        try:\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.8 * n.distance:\n",
    "                    good.append(m)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # Get the image points form the good matches\n",
    "        q1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
    "        q2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "\n",
    "        # normalizing points about the sphere of radius 1.\n",
    "        q1 = normalize_point(q1)\n",
    "        q2 = normalize_point(q2)\n",
    "\n",
    "        theta, phi = find_theta_phi(q1, q2)\n",
    "        theta_deg = theta * 180 / np.pi\n",
    "\n",
    "        if abs(theta_deg) < THETA_THRES:\n",
    "            # no motion detected.\n",
    "            right += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        rho = (D_COM * np.sin(phi) - D_COM * np.sin(phi - theta)) / np.sin(phi - theta/2.)\n",
    "\n",
    "        if rho < 0:\n",
    "            left = right\n",
    "            right += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        k = 2 * np.sin(theta / 2.) / rho\n",
    "        curvatures.append({\n",
    "            \"value\": k,\n",
    "            \"left\": left,\n",
    "            \"right\": right,\n",
    "            \"rho\": rho\n",
    "        })\n",
    "\n",
    "        left = right\n",
    "        right += 1\n",
    "        pbar.update(1)\n",
    "    \n",
    "    print(f\"A total of {len(curvatures)} curvatures were extracted.\")\n",
    "\n",
    "    # now we select which curvatures depict a circular motion.\n",
    "    mask = []\n",
    "    for i in range(len(curvatures)-1):\n",
    "        val = abs(curvatures[i][\"value\"] - curvatures[i+1][\"value\"]) / abs(curvatures[i][\"value\"])\n",
    "        if val < 0.1:\n",
    "            mask.append(1)\n",
    "        else:\n",
    "            mask.append(0)\n",
    "    \n",
    "    circulars = []\n",
    "    for i in range(len(mask)):\n",
    "        if mask[i] == 1:\n",
    "            circulars.append(curvatures[i])\n",
    "    \n",
    "    print(f\"A total of {len(circulars)} circular motions were extracted.\")\n",
    "\n",
    "    # create a list of possible absolute scales and plot a histogram.\n",
    "    rhos = []\n",
    "    for circ in circulars:\n",
    "        rho = circ[\"rho\"]\n",
    "        rhos.append(rho)\n",
    "\n",
    "    return rhos, circulars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the subset frames present at 'demo/turn/'\n",
    "img_path = \"demo/turn/images/\"\n",
    "image_paths = sorted(os.listdir(img_path))\n",
    "images = []\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(img_path + \"/\" + path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 690/691 [01:40<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 354 curvatures were extracted.\n",
      "A total of 15 circular motions were extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rhos, circulars = absolute_scale(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted absolute scale: 0.27965190323954897\n"
     ]
    }
   ],
   "source": [
    "# creating a histogram of rhos.\n",
    "counts, bins = np.histogram(rhos, bins=5)\n",
    "\n",
    "# now we extract the bin value with highest frequency.\n",
    "# note that this just a heuristic to remove the affect\n",
    "# of possible outliers / wrong predictions. this method\n",
    "# can definitely be improved by using some more robust\n",
    "# techniques.\n",
    "idxs = np.argsort(counts)\n",
    "rho_prediction = bins[idxs[-1]]\n",
    "print(\"Predicted absolute scale:\", rho_prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large{}\n",
    "\\text{Visual Odometry} \\\\\n",
    "\\normalsize{} \\\\\n",
    "\\text{Visual Odometry is the process of reconstructing the camera path through visual input / video. The VO is calculated in a relative scale.} \\\\\n",
    "\\text{However, since we have estimated an absolute scale we have the information to construct an odometry in the absolute scale.}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.odometry.visual_odometry import VisualOdometry\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 691/691 [01:12<00:00, 10.09it/s]"
     ]
    }
   ],
   "source": [
    "odometry = VisualOdometry(\"demo/turn\", rho_prediction)\n",
    "estimated_path = []\n",
    "\n",
    "if not os.path.exists(Path(RESULTS_DIR) / \"odometry\"):\n",
    "    os.mkdir(Path(RESULTS_DIR) / \"odometry\")\n",
    "\n",
    "pbar = tqdm(total=len(images))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    if i == 0:\n",
    "        curr_pose = np.eye(4)\n",
    "    else:\n",
    "        q1, q2 = odometry.get_matches(i)\n",
    "        transf, _, _, _ = odometry.get_pose(q1, q2)\n",
    "        curr_pose = np.matmul(curr_pose, np.linalg.inv(transf))\n",
    "        estimated_path.append((curr_pose[0, 3], curr_pose[2, 3]))\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the absolute scaled trajectory.\n",
    "estimated_path = np.array(estimated_path)\n",
    "fig = plt.figure()\n",
    "plt.title(\"Estimated Trajectory around corner.\")\n",
    "plt.scatter(estimated_path[:,0], estimated_path[:,1])\n",
    "# TODO: plot circulars.\n",
    "plt.gca().set_xlim(-100, 100)\n",
    "plt.gca().set_ylim(-100, 100)\n",
    "plt.grid(\"minor\")\n",
    "plt.xlabel(\"x (in meters)\")\n",
    "plt.ylabel(\"y (in meters)\")\n",
    "plt.savefig(\"results/odometry/vo.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated trajectory is saved in `results/odometry/vo.png`. Also, take a look at the images present in `demo/turn/images` for getting\n",
    "an idea about the actual trajectory. As we can observe, the actual trajectory (as observed visually) is very similar to the estimated one.\n",
    "In fact, the scale of the estimated trajectory is absolute. This means that we can exactly measure the location (in meters) of the car\n",
    "at any point in its journey. Also, we can correlate this frame-by-frame data along with the detection and tracking data obtained earlier\n",
    "and predict the exact coordinates of a particular pothole, thus flagging it efficiently.\n",
    "\n",
    "We can also provide this functionality in real-time by using a faster algorithm. Again, this [paper](https://drops.dagstuhl.de/opus/volltexte/2011/2950/pdf/10371.ScaramuzzaDavide.Paper.2950.pdf) by David Scaramuzza can prove to be useful in this case. He solves the problem of visual odometry in real-time, using a 1-point RANSAC algorithm that exploits the non-holonomic constraints of the car."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\large{}\n",
    "\\text{3D Reconstruction} \\\\\n",
    "\\normalsize{} \\\\\n",
    "\\text{The final part of the pipeline can be to create a 3 dimensional reconstruction of a pothole. Structure From Motion is the most} \\\\\n",
    "\\text{popular technique that is used to create 3D point clouds using multiple photos. However, our problem is of a special kind.} \\\\\n",
    "\\text{We have to model the road surface which is a near-planar surface. Due to this planarity, an ambiguity arises in the calculation} \\\\\n",
    "\\text{of the Fundamental Matrix. Therefore, the normal equations of SFM might not produce great results in our case.}\n",
    "$\n",
    "To know more about how near-planar surfaces cause this ambiguity, this [paper](https://www.mdpi.com/1424-8220/20/6/1640) proves the same.\n",
    "The paper also derives a new unambiguous equation for calculating the fundamental matrix using the homography matrix.\n",
    "Further, this paper also provides a great recursive post-processing technique on pothole point clouds that can improve the structure\n",
    "of the reconstruction even more. Unfortunately due to time-constraint, I was unable to implement this paper on the given demo video.\n",
    "\n",
    "\n",
    "So, I used a software known as VisualSFM for dense point-cloud reconstruction for different images of the same pothole. This was comparitively easy and less complex as I was already detecting and tracking the potholes. So, using the bounding boxes I extracted the pothole (whose 3d reconstruction is to be done) from all the frames in which it was tracked. This lead to a collection of different images for every pothole, from different viewing angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frame</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5043.0</td>\n",
       "      <td>89</td>\n",
       "      <td>285.194881</td>\n",
       "      <td>640.341441</td>\n",
       "      <td>508.731961</td>\n",
       "      <td>779.049773</td>\n",
       "      <td>D20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5049.0</td>\n",
       "      <td>105</td>\n",
       "      <td>1222.791426</td>\n",
       "      <td>535.750690</td>\n",
       "      <td>1329.495472</td>\n",
       "      <td>579.264288</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5049.0</td>\n",
       "      <td>106</td>\n",
       "      <td>1233.636628</td>\n",
       "      <td>545.713590</td>\n",
       "      <td>1343.380073</td>\n",
       "      <td>590.756086</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5050.0</td>\n",
       "      <td>107</td>\n",
       "      <td>-20.779910</td>\n",
       "      <td>602.979566</td>\n",
       "      <td>489.229553</td>\n",
       "      <td>1005.932807</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5049.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1247.344331</td>\n",
       "      <td>555.332061</td>\n",
       "      <td>1359.689536</td>\n",
       "      <td>601.389324</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  frame         xmin        ymin         xmax         ymax class\n",
       "0  5043.0     89   285.194881  640.341441   508.731961   779.049773   D20\n",
       "1  5049.0    105  1222.791426  535.750690  1329.495472   579.264288   D40\n",
       "2  5049.0    106  1233.636628  545.713590  1343.380073   590.756086   D40\n",
       "3  5050.0    107   -20.779910  602.979566   489.229553  1005.932807   D40\n",
       "4  5049.0    107  1247.344331  555.332061  1359.689536   601.389324   D40"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_df = pd.read_csv(\"results/detection/detections.csv\")\n",
    "detections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frame</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>639.380196</td>\n",
       "      <td>539.716118</td>\n",
       "      <td>833.364392</td>\n",
       "      <td>582.382895</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>611.615343</td>\n",
       "      <td>547.548653</td>\n",
       "      <td>824.376084</td>\n",
       "      <td>595.556804</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>7</td>\n",
       "      <td>127</td>\n",
       "      <td>586.161660</td>\n",
       "      <td>552.729840</td>\n",
       "      <td>822.513836</td>\n",
       "      <td>608.677686</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>572.135991</td>\n",
       "      <td>563.758007</td>\n",
       "      <td>813.180840</td>\n",
       "      <td>623.176119</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>555.808030</td>\n",
       "      <td>578.041087</td>\n",
       "      <td>812.014631</td>\n",
       "      <td>643.019943</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>7</td>\n",
       "      <td>130</td>\n",
       "      <td>538.208653</td>\n",
       "      <td>593.624555</td>\n",
       "      <td>807.808649</td>\n",
       "      <td>663.475136</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7</td>\n",
       "      <td>131</td>\n",
       "      <td>547.344992</td>\n",
       "      <td>620.533102</td>\n",
       "      <td>802.444096</td>\n",
       "      <td>687.079139</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>132</td>\n",
       "      <td>529.844143</td>\n",
       "      <td>642.336836</td>\n",
       "      <td>785.561134</td>\n",
       "      <td>710.263165</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>514.626662</td>\n",
       "      <td>666.427805</td>\n",
       "      <td>773.031477</td>\n",
       "      <td>736.881315</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7</td>\n",
       "      <td>134</td>\n",
       "      <td>487.764412</td>\n",
       "      <td>693.102580</td>\n",
       "      <td>755.764575</td>\n",
       "      <td>767.769809</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7</td>\n",
       "      <td>135</td>\n",
       "      <td>446.024936</td>\n",
       "      <td>720.749031</td>\n",
       "      <td>732.852272</td>\n",
       "      <td>803.554656</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>7</td>\n",
       "      <td>136</td>\n",
       "      <td>399.812903</td>\n",
       "      <td>756.784818</td>\n",
       "      <td>706.883955</td>\n",
       "      <td>847.776911</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>343.306560</td>\n",
       "      <td>798.885971</td>\n",
       "      <td>676.702865</td>\n",
       "      <td>901.491118</td>\n",
       "      <td>D40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  frame        xmin        ymin        xmax        ymax class\n",
       "43    7    125  639.380196  539.716118  833.364392  582.382895   D40\n",
       "50    7    126  611.615343  547.548653  824.376084  595.556804   D40\n",
       "58    7    127  586.161660  552.729840  822.513836  608.677686   D40\n",
       "66    7    128  572.135991  563.758007  813.180840  623.176119   D40\n",
       "74    7    129  555.808030  578.041087  812.014631  643.019943   D40\n",
       "82    7    130  538.208653  593.624555  807.808649  663.475136   D40\n",
       "90    7    131  547.344992  620.533102  802.444096  687.079139   D40\n",
       "97    7    132  529.844143  642.336836  785.561134  710.263165   D40\n",
       "104   7    133  514.626662  666.427805  773.031477  736.881315   D40\n",
       "111   7    134  487.764412  693.102580  755.764575  767.769809   D40\n",
       "117   7    135  446.024936  720.749031  732.852272  803.554656   D40\n",
       "123   7    136  399.812903  756.784818  706.883955  847.776911   D40\n",
       "129   7    137  343.306560  798.885971  676.702865  901.491118   D40"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POTHOLE_CLASS = \"D40\"\n",
    "POTHOLE_ID = 7\n",
    "\n",
    "pothole_12 = detections_df.loc[(detections_df[\"id\"] == POTHOLE_ID) & (detections_df[\"class\"] == POTHOLE_CLASS), :]\n",
    "pothole_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3844/3844 [03:04<00:00, 20.87it/s] \n",
      " 99%|█████████▉| 3824/3844 [00:17<00:00, 222.69it/s]"
     ]
    }
   ],
   "source": [
    "pothole_crops = []\n",
    "\n",
    "# relax bbox to also get some surroundings.\n",
    "relax = 40\n",
    "\n",
    "cap = cv2.VideoCapture(DEMO_VIDEO)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Could not read the video!!!\")\n",
    "\n",
    "num_frames = 0\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=length)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        if num_frames in pothole_12.loc[:, \"frame\"].to_list():\n",
    "            bbox = pothole_12.loc[pothole_12[\"frame\"] == num_frames, [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]]\n",
    "            xmin, xmax, ymin, ymax = int(bbox[\"xmin\"]), int(bbox[\"xmax\"]), int(bbox[\"ymin\"]), int(bbox[\"ymax\"])\n",
    "            pothole_cropped = img[xmin-relax:xmax+relax, ymin-relax:ymax+relax].copy()\n",
    "            pothole_crops.append(pothole_cropped)\n",
    "\n",
    "        num_frames += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(Path(RESULTS_DIR) / \"reconstruction\"):\n",
    "    os.mkdir(Path(RESULTS_DIR) / \"reconstruction\")\n",
    "\n",
    "if not os.path.exists(Path(RESULTS_DIR) / \"reconstruction\" / \"images\"):\n",
    "    os.mkdir(Path(RESULTS_DIR) / \"reconstruction\" / \"images\")\n",
    "\n",
    "for idx,crop in enumerate(pothole_crops):\n",
    "    cv2.imwrite((Path(RESULTS_DIR) / \"reconstruction\" / \"images\" / f\"{idx}.png\").as_posix(), crop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting cropped images can then be used with VisualSFM or any other SFM tool.\n",
    "\n",
    "$\n",
    "\\large{Conclusion} \\\\\n",
    "\\normalsize{} \\\\\n",
    "\\text{As we observed that, even by using a single video source, we can generate a lot of analysis about the surrounding. The detection} \\\\\n",
    "\\text{aspect of this approach is definitely more mature. We can even say that the accuracy obtained through pothole detection and tracking} \\\\\n",
    "\\text{can be at least as good as LIDAR if not better. Moreover, the overall infrastructure required to setup this is negligible and} \\\\\n",
    "\\text{this can even be deployed on smartphones. The solution is completely autonomous as there is no input required from a human.} \\\\\n",
    "\\text{From object detection and tracking to 3d reconstruction, everything can be done automatically using different heuristics. A human} \\\\\n",
    "\\text{is needed only in a supervising capacity.}\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:39:05) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fda91435a63222b52375ad7febdc25de7c9894bc34f4edc19503b4a62645f0aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
